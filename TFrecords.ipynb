{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "test=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num = 10\n",
    "val_percentage = 0.1\n",
    "test_percentage = 0.1\n",
    "\n",
    "#helper functions for the features.\n",
    "def _int64_feature(value):\n",
    "#Wrapper for inserting int64 features into Example proto.\n",
    "    if not isinstance(value, list):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "#Wrapper for inserting bytes features into Example proto.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "\n",
    "def image_example(image_string, label):\n",
    "#creates the example to write in the TFrecords file\n",
    "    image_shape = tf.image.decode_image(image_string)\n",
    "    feature = {\n",
    "      'height': _int64_feature(image_shape.shape[0]),\n",
    "      'width': _int64_feature(image_shape.shape[1]),\n",
    "      'depth': _int64_feature(image_shape.shape[2]),\n",
    "      'label': _int64_feature(label),\n",
    "      'image_raw': _bytes_feature(image_string),\n",
    "  }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "\n",
    "def randomize_data(folder_path, record_file, val_percentage = 0.1, test_percentage = 0.1, class_num = 10):\n",
    "#creates a randomised vector to choose files for validation and test data\n",
    "    file_num = 0\n",
    "    for i in range(class_num):\n",
    "        folder = i\n",
    "        data_folder = Path(folder_path + \"/%d\" %folder)\n",
    "        directory = os.fsencode(data_folder) \n",
    "        for file in os.listdir(directory):\n",
    "            file_num +=1\n",
    "    np.random.seed(126)\n",
    "    randomized = np.random.choice(file_num, int(file_num * (val_percentage + test_percentage)), replace = False)\n",
    "    to_val = np.sort(np.random.choice(randomized, int(file_num * val_percentage), replace = False))\n",
    "    to_test = np.sort([x for x in randomized if x not in to_val])\n",
    "    lim_val = len(to_val) - 1\n",
    "    lim_test = len(to_test) - 1 \n",
    "    return to_val, lim_val, to_test, lim_test, file_num\n",
    "\n",
    "def create_val(folder_path, record_file, to_val, lim_val, class_num = 10):\n",
    "#creates the validation data tfrecords file\n",
    "    idx = 0\n",
    "    buffer_size=0\n",
    "    file_name = 'val_' + record_file\n",
    "    with tf.io.TFRecordWriter(file_name) as writer_val:\n",
    "        for i in range(class_num):\n",
    "            folder = i\n",
    "            data_folder = Path(folder_path + \"/%d\" %folder)\n",
    "            directory = os.fsencode(data_folder) \n",
    "            for file in os.listdir(directory):\n",
    "                filename = data_folder / os.fsdecode(file)\n",
    "                image_string = open(filename,'rb').read()\n",
    "                label = folder\n",
    "                tf_example = image_example(image_string, label)\n",
    "                if buffer_size == to_val[idx]:\n",
    "                    writer_val.write(tf_example.SerializeToString())\n",
    "                    if idx!=lim_val:\n",
    "                        idx +=1\n",
    "                buffer_size +=1\n",
    "\n",
    "def create_train(folder_path, record_file, to_val, lim_val,to_test, lim_test, class_num = 10):\n",
    "#creats the training data tfrecords file\n",
    "    idx_val = 0\n",
    "    idx_test = 0\n",
    "    buffer_size=0\n",
    "    file_name = 'train_' + record_file                    \n",
    "    with tf.io.TFRecordWriter(file_name) as writer_train:\n",
    "        for i in range(class_num):\n",
    "            folder = i\n",
    "            data_folder = Path(folder_path + \"/%d\" %folder)\n",
    "            directory = os.fsencode(data_folder) \n",
    "            for file in os.listdir(directory):\n",
    "                filename = data_folder / os.fsdecode(file)\n",
    "                image_string = open(filename,'rb').read()\n",
    "                label = folder\n",
    "                tf_example = image_example(image_string, label)\n",
    "                if buffer_size != to_val[idx_val] and buffer_size!=to_test[idx_test]:\n",
    "                    writer_train.write(tf_example.SerializeToString())\n",
    "                elif buffer_size == to_val[idx_val]:\n",
    "                    if idx_val!=lim_val:\n",
    "                        idx_val +=1\n",
    "                else:\n",
    "                    if idx_test!=lim_test:\n",
    "                        idx_test +=1\n",
    "                buffer_size +=1\n",
    "\n",
    "def create_test(folder_path, record_file, to_test, lim_test, class_num = 10, test_percentage = 0.1):\n",
    "#creats the test data tfrecords file\n",
    "    idx = 0\n",
    "    buffer_size=0\n",
    "    file_name = 'test_' + record_file                    \n",
    "    with tf.io.TFRecordWriter(file_name) as writer_test:\n",
    "        for i in range(class_num):\n",
    "            folder = i\n",
    "            data_folder = Path(folder_path + \"/%d\" %folder)\n",
    "            directory = os.fsencode(data_folder) \n",
    "            for file in os.listdir(directory):\n",
    "                filename = data_folder / os.fsdecode(file)\n",
    "                image_string = open(filename,'rb').read()\n",
    "                label = folder\n",
    "                tf_example = image_example(image_string, label)\n",
    "                if buffer_size == to_test[idx]:\n",
    "                    writer_test.write(tf_example.SerializeToString())\n",
    "                    if idx!=lim_test:\n",
    "                        idx +=1\n",
    "                buffer_size +=1                \n",
    "        \n",
    "                \n",
    "        \n",
    "\n",
    "record_file = 'minst.tfrecords'\n",
    "folder_path = 'mnist data/trainingSet/trainingSet'\n",
    "to_val, lim_val , to_test, lim_test = randomize_data(folder_path, record_file, val_percentage, test_percentage ,class_num)\n",
    "create_val(folder_path, record_file, to_val, lim_val, class_num)\n",
    "create_train(folder_path, record_file, to_val, lim_val,to_test, lim_test, class_num)\n",
    "create_test(folder_path, record_file, to_test, lim_test, class_num, test_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def convert_back(data_type,buffer_size,record_file,val_percentage=0.1, test_percentage = 0.1, channels =1, img_size = (28,28)):\n",
    "# converts the tfrecords files to images and labels and returns the parsed dataset\n",
    "    def _parse_image_function(example_proto):\n",
    "        # Parse the input tf.Example proto using the dictionary above.\n",
    "        # Create a dictionary describing the features.\n",
    "        image_feature_description = {\n",
    "            'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "        }\n",
    "        image_features = tf.io.parse_single_example(example_proto,image_feature_description)\n",
    "        image_buffer = image_features['image_raw']\n",
    "        image = tf.image.decode_jpeg(image_buffer,channels = channels)\n",
    "        image = tf.image.convert_image_dtype(image,dtype=tf.float32)*(1. / 255)\n",
    "        image_shape = tf.stack([img_size[0],img_size[1],channels])\n",
    "        image = tf.reshape(image,image_shape)\n",
    "        label = tf.cast(image_features['label'],tf.uint8)\n",
    "        label = tf.squeeze(label)\n",
    "        return image,label\n",
    "    \n",
    "    batch_size = 32\n",
    "    num_parallel_batches = 2\n",
    "    if data_type == 'val':\n",
    "        buffer = int(buffer_size * val_percentage)\n",
    "    elif data_type == 'test':\n",
    "        buffer = int(buffer_size * test_percentage)\n",
    "    else:\n",
    "        buffer = buffer_size\n",
    "    raw_image_dataset = tf.data.TFRecordDataset(data_type+ '_' + record_file)\n",
    "    raw_image_dataset = raw_image_dataset.shuffle(buffer)\n",
    "    parsed_image_dataset = raw_image_dataset.map(_parse_image_function, num_parallel_calls = num_parallel_batches)\n",
    "    parsed_image_dataset = parsed_image_dataset.batch(batch_size)\n",
    "    parsed_image_dataset = parsed_image_dataset.prefetch(1)\n",
    "    return parsed_image_dataset\n",
    "\n",
    "\n",
    "record_file = 'minst.tfrecords'\n",
    "folder_path = 'mnist data/trainingSet/trainingSet'\n",
    "_, _,_, buffer_size = randomize_data(folder_path, record_file, val_percentage, test_percentage, class_num)\n",
    "val_ds = convert_back('val',buffer_size = buffer_size, record_file = record_file)\n",
    "train_ds = convert_back('train',buffer_size = buffer_size, record_file = record_file)\n",
    "test_ds = convert_back('test',buffer_size = buffer_size, record_file = record_file)\n",
    "\n",
    "#sanity check\n",
    "if test:\n",
    "    for image, label in test_ds.take(1):\n",
    "        print(image.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = 32\n",
    "kernels = (3,3)\n",
    "pools = (3,3)\n",
    "dense1 = 128\n",
    "dense2 = 64\n",
    "last_dense = 10\n",
    "dropout1 = 0.4\n",
    "dropout2 = 0.4\n",
    "\n",
    "#creating the model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Conv2D(filters, kernel_size=kernels, padding='same', input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=pools, padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(dense1, activation='relu'))\n",
    "model.add(Dropout(dropout1))\n",
    "model.add(Dense(dense2, activation='relu'))\n",
    "model.add(Dropout(dropout2))\n",
    "model.add(Dense(last_dense, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', metrics=['sparse_categorical_accuracy'], loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 1.1150 - sparse_categorical_accuracy: 0.6049 - val_loss: 2.2024 - val_sparse_categorical_accuracy: 0.4412\n",
      "Epoch 2/10\n",
      "1050/1050 [==============================] - 3s 3ms/step - loss: 0.4078 - sparse_categorical_accuracy: 0.8737 - val_loss: 1.2739 - val_sparse_categorical_accuracy: 0.6121\n",
      "Epoch 3/10\n",
      "1050/1050 [==============================] - 3s 3ms/step - loss: 0.2455 - sparse_categorical_accuracy: 0.9299 - val_loss: 0.7834 - val_sparse_categorical_accuracy: 0.7788\n",
      "Epoch 4/10\n",
      "1050/1050 [==============================] - 3s 3ms/step - loss: 0.2099 - sparse_categorical_accuracy: 0.9390 - val_loss: 0.7599 - val_sparse_categorical_accuracy: 0.7798\n",
      "Epoch 5/10\n",
      "1050/1050 [==============================] - 3s 3ms/step - loss: 0.1878 - sparse_categorical_accuracy: 0.9450 - val_loss: 0.6728 - val_sparse_categorical_accuracy: 0.8195\n",
      "Epoch 6/10\n",
      "1050/1050 [==============================] - 4s 3ms/step - loss: 0.1743 - sparse_categorical_accuracy: 0.9502 - val_loss: 0.5959 - val_sparse_categorical_accuracy: 0.8295\n",
      "Epoch 7/10\n",
      "1050/1050 [==============================] - 4s 3ms/step - loss: 0.1650 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.5796 - val_sparse_categorical_accuracy: 0.8414\n",
      "Epoch 8/10\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1528 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.4582 - val_sparse_categorical_accuracy: 0.8624\n",
      "Epoch 9/10\n",
      "1050/1050 [==============================] - 4s 4ms/step - loss: 0.1470 - sparse_categorical_accuracy: 0.9586 - val_loss: 0.5893 - val_sparse_categorical_accuracy: 0.8286\n",
      "Epoch 10/10\n",
      "1050/1050 [==============================] - 4s 3ms/step - loss: 0.1379 - sparse_categorical_accuracy: 0.9596 - val_loss: 0.4632 - val_sparse_categorical_accuracy: 0.8652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x273bbcf1d48>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=10, validation_data = val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    132/Unknown - 0s 4ms/step - loss: 0.4767 - sparse_categorical_accuracy: 0.8595"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4766711139430602, 0.85952383]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
